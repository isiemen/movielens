---
title: "Movielens Capstone Final"
author: "Irene Siemen"
date: "5/20/2020"
output: pdf_document
---

## Introduction:

The MovieLens dataset contains thousands of movie ratings that were given by specific users. The dataset includes the user ID, movie ID, movie title, rating on scale of 0 to 5, movie genre, and the timestamp asscociated with the date that review was created. The goal of this project was to predict the rating that a user will give a movie. The predictions were generated by creating and training a machine learning algorithm using a subset of the data, then creating predictions on the validation data set. The success of the machine learning algorithm was evaluated using the root mean square error (RMSE).

The first step was to complete exploratory data analysis (EDA) on the training data set to review the data. The EDA included reviewing the characteristics of the variables, checking for NaNs, performing filters and counts, and graphing the relationships between variables. The EDA revealed trends in the data, such as some users prefer specific genres, and these trends were used to establish baseline bias values. Once the genres were split and the bias were calculated, then a random forest model was created to determine the components that most affect the rating. The fitted random forest model was used to create predictions on the training and test data and returned a desirable RMSE value. Finally, the random forest model was used to create predictions for the validation data set and calculate the final RMSE value.

## Methods and Analysis:

#### Data Wrangling

The first step was to import the data, then partition out test and validation data sets from the training data. Then, some basic data wrangling was completed on the training data. This included extracting the movie’s release year from the title column, converting the timestamp variable to a date format and extracting the year, and removing any NaN values.

```{r import_data, include=FALSE}
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyverse)
library(randomForest)
library(caret)
library(data.table)
library(viridis)
library(tidyr)
library(plyr)
options(digits = 6)
memory.limit(200000)

#access the data files locally:
ratings <- fread(text = gsub("::", "\t", readLines("C:/Users/isiemen/Documents/ml-10M100K/ratings.dat")),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines( "C:/Users/isiemen/Documents/ml-10M100K/movies.dat"), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")
```

```{r partition_data, include=FALSE}
#Extract year from title, convert timestamp to date and year
movielens<-movielens%>%mutate(review_date = as.Date(as.POSIXct(timestamp, origin="1970-01-01")),
                              review_year = as.integer(format(review_date,"%Y")),
                              movie_year = as.integer(str_extract(str_sub(title, -5),"\\d{4}")),
                              n_years_release_review = as.numeric(review_year)-as.numeric(movie_year))

# Validation set will be 10% of MovieLens data
set.seed(1)
temp_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-temp_index,]
temp <- movielens[temp_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
rm( ratings, movies, temp_index, temp, movielens, removed)

# Create a test data set that is 10% of the edx dataset
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
edx <- edx[-test_index,]
test <- edx[test_index,]

```

#### EDA

The next step was to complete exploratory data analysis (EDA) on the training data set to review the data. The EDA included reviewing the characteristics of the variables, checking for NaNs, performing filters and counts, and graphing the relationships between variables. The EDA revealed trends in the data, such as some movies are higher rated than others, and these trends were used to establish baseline bias values. 
The first graphs created were two histograms that show the distribution of ratings; one histogram is grouped by users and the other histogram is grouped by movies. The distribution is similiar between the two groupings.


```{r, echo=FALSE}
#Plot userId vs Rating
edx%>%group_by(userId)%>%
  dplyr::summarize(avg_rating = mean(rating))%>%
  ggplot(aes(avg_rating))+
  geom_histogram(bins=10)+
  ggtitle("Average Rating Given by User")+
  xlab("Average Rating")+
  ylab("Number of Users")

#Plot movieId vs Rating
edx%>%group_by(movieId)%>%
  dplyr::summarize(avg_rating = mean(rating))%>%
  ggplot(aes(avg_rating))+
  geom_histogram(bins=10)+
  ggtitle("Average Rating Given by Movie")+
  xlab("Average Rating")+
  ylab("Number of Movies")
```

The next step of the EDA was to see if genre appeared to affect ratings. Each movie could be associated with one or more genres. A list of distinct individual genres was created with a summary of count and average. Then, a scatterplot showed the average rating of all movies that listed each genre.  It appeared that genre marginally affected the movie’s rating, although difference in average rating decrees as the number of ratings increases. The genre column was separated into individual binary columns for each specific genre to allow for easier computations.

```{r, include=FALSE}
#Create a list of unique words in the genres column
genre_list<-str_split(edx$genres,pattern="\\|",simplify = TRUE)
genre_list<-as.data.frame(genre_list)%>%
  gather(genre_list)

genre_list<-genre_list%>%
  distinct(value)

#number of reviews and average rating per genre
genre_summary<-function(x){
  tab<-edx%>%mutate(match=str_count(edx$genres,x))%>%filter(match==1)
  n<-sum(tab$match)
  avg_rating<-mean(tab$rating)
  data.frame(n=n,rating=avg_rating,genre=x)
}
genre_tab<-rbind.fill(apply(genre_list,FUN=genre_summary,MARGIN = 1))%>%
  arrange(desc(n))
genre_tab
```

```{r, echo=FALSE}
genre_tab%>%ggplot(aes(x=rating,y=n,color=genre, label = genre))+
  geom_point()+
  geom_text( nudge_x = 0.07)+
  ggtitle("Average Rating and Total Reviews by Genre")+
  xlab("Average Rating")+
  ylab("Total Reviews")+
  theme(legend.position = "none")
```

Since some variation in the average rating for each genre, it was decided to look at genre variation among users and see if different users prefer different genres. The top 4 most reviewed genres were drama, comedy, thriller and action. These genres were associated with 94% of the movies in the training data. Boxplots were created showing the rating distributions for these genres faceted by the 12 users who had left the most reviews. The chart shows that some users rate all genres the same and other users have distinct genre preferences.

```{r, echo=FALSE}
#boxplot of top 12 users and their ratings for top 4 genres
top_12_users<-edx%>%group_by(userId)%>%
  dplyr::summarize(n = n())%>%
  arrange(desc(n))%>%
  top_n(12)

edx_genre<-edx%>%
  filter(userId %in% top_12_users$userId,
         str_count(genres,"Drama")==1 |
           str_count(genres,"Comedy")==1 |
           str_count(genres,"Action")==1 |
           str_count(genres,"Thriller")==1)%>%
  mutate(Drama=case_when(str_count(genres,"Drama")==1 ~ rating, TRUE ~ 0),
         Comedy = case_when(str_count(genres,"Comedy")==1 ~ rating, TRUE ~ 0),
         Action=case_when(str_count(genres,"Action")==1 ~ rating, TRUE ~ 0),
         Thriller=case_when(str_count(genres,"Thriller")==1 ~ rating, TRUE ~ 0))%>%
  gather(top_genre,genre_rating,c("Drama","Comedy","Action","Thriller"))%>%
  filter(genre_rating!=0)


edx_genre%>%ggplot(aes(top_genre,genre_rating, fill=top_genre))+
  geom_boxplot()+
  facet_wrap(.~userId)+
  geom_boxplot(alpha=0.05)+
  theme(legend.position = "none",axis.text.x = element_text(angle = 75, hjust = 1))+
  ggtitle("Genre Ratings per User ID")+
  ylab("Movie Ratings")+
  xlab("Genre")
```

Another scatterplot was created to compare the number of reviews per movie to the average rating. The plot illustrated that movies with fewer reviews have a wider range of ratings and that average rating increased as the number of ratings increased. This makes sense because popular movies tend to have better ratings.

```{r, echo=FALSE}
edx%>%group_by(movieId,title)%>%
  dplyr::summarize(n=n(),
                   avg_rating = mean(rating))%>%
  arrange(desc(n))%>%
  ggplot(aes(n,avg_rating, color = avg_rating))+
  geom_point()+
  geom_smooth(color = "black", alpha = 0.5, method = "lm")+  
  ggtitle("Average Rating and Total Reviews")+
  xlab("Number of Reviews")+
  ylab("Average Rating")+
  theme(legend.position = "none")
```

Timeseries plots were created to see if a movie’s or user’s average rating changed over time. One plot showed the average rating over time for the ten most rated movies and the other for the ten users who left the most reviews. A movie’s ratings appear to decrease over the years. However, there is not a strong trend in how users’ ratings change over the years.

```{r, echo=FALSE}
#Plot movie ratings overtime for the top 10 movies with the most reviews
top_10_movies<-edx%>%group_by(title)%>%
  dplyr::summarize(n = n())%>%
  arrange(desc(n))%>%
  top_n(10)

movies_year<-edx%>%filter(title %in% top_10_movies$title)%>%
  mutate(year = year(review_date))%>%
  group_by(year, title)%>%
  dplyr::summarize(avg_rating = mean(rating))

movies_year%>%
  ggplot(aes(year,avg_rating,group = title, color = title, label = title))+
  geom_line()+
  ggtitle("Movie Ratings Over Time")+
  xlab("Year")+
  ylab("Rating")+
  theme_minimal()+
  scale_color_viridis(discrete = TRUE, option = "D")+
  theme(legend.position = "none")
```

Finally, a line graph was created to see if movies released in certain years tend to have higher rated movies.

```{r, echo=FALSE}
#Line graph of average movie rating per movie release year
edx%>%mutate(movie_year = as.integer(movie_year))%>%
  group_by(movie_year)%>%
  dplyr::summarize(avg_rating = mean(rating))%>%
  ggplot(aes(movie_year,avg_rating))+
  geom_line()+ 
  ggtitle("Average Movie Rating per Year of Movie Release")+
  xlab("Year Movie was Released")+
  ylab("Average Rating")+
  theme_minimal()+
  theme(legend.position = "none")

```

####BIAS PREDICTORS
The EDA revealed trends in the data such as some movies are higher rated than others, certain users tend to leave higher reviews than other, movie ratings tend to decrease over time, and users prefer specific genres. Four columns were added: Drama, Comedy, Action, and Thriller. These genres are associated with 94% of the movies in the training data. If one or more of these genres were associated with the movie, then the rating was copied to the appropriate column.

```{r, genre_columns}
#Add genre rating for top 4 genres to the edx dataframe
edx<-edx%>%filter(str_count(genres,"Drama")==1 |
                    str_count(genres,"Comedy")==1 |
                    str_count(genres,"Action")==1 |
                    str_count(genres,"Thriller")==1)%>%
  mutate(Drama=case_when(str_count(genres,"Drama")==1 ~ rating, TRUE ~ 0),
         Comedy = case_when(str_count(genres,"Comedy")==1 ~ rating, TRUE ~ 0),
         Action=case_when(str_count(genres,"Action")==1 ~ rating, TRUE ~ 0),
         Thriller=case_when(str_count(genres,"Thriller")==1 ~ rating, TRUE ~ 0))
```

Nine bias predictors were calculated for the training data set: mean rating of a specific movie, mean rating of a specific user, mean rating for the year a movie was released, mean rating based on the number of reviews, and user’s mean rating for the genres of drama, comedy, action and thriller. The value of each bias was calculated by subtracting the mean of movies (mu_rating) from mean of the specific bias group. 


```{r, bias}
#Establish the baseline bias predictors for the rating. For example, the mean rating for all movies, etc.
#Baseline 1: the average rating for all movies
mu_rating<-mean(edx$rating) 

#Basline 2: the movie bias. Calculate difference between a specific movie's rating and the average rating
movie_avgs <- edx %>%  # calulate the movie bias
  group_by(movieId) %>% 
  dplyr::summarize(movie_bias = mean(rating - mu_rating))

#Baseline 3: the user bias: calculate the difference between a specific user's average rating and the overall average rating
user_avgs <- edx %>%  # calulate the user bias
  group_by(userId) %>% 
  dplyr::summarize(user_bias = mean(rating - mu_rating))


#Baseline 4: Number of Reviews bias: The number of reviews effects the average rating
n_ratings<-edx%>%
  group_by(movieId)%>%
  dplyr::summarize(n=n(),
                   avg_rating = mean(rating))

fit_lm_n_rating<-lm(avg_rating ~ n,data=n_ratings)
slope_n<-summary(fit_lm_n_rating)$coef[2,1]
intercept_n<-summary(fit_lm_n_rating)$coef[1,1]

n_ratings<-n_ratings%>%
  dplyr::mutate(y_hat_nratings = intercept_n+(n*slope_n),
                n_ratings_bias = mean(y_hat_nratings-mu_rating))

#Baseline 5: The year the movie was released effects the average rating
movie_year_avgs <- edx %>%
  group_by(movie_year) %>% 
  dplyr::summarize(movie_year_bias = mean(rating - mu_rating))
movie_year_avgs

#Baseline 6: User-Genre Bias
drama_avgs <-edx%>%
  group_by(userId)%>%
  filter(Drama!=0)%>%
  dplyr::summarize(drama_bias = mean(Drama-mu_rating))

comedy_avgs <-edx%>%
  group_by(userId)%>%
  filter(Comedy!=0)%>%
  dplyr::summarize(comedy_bias = mean(Comedy-mu_rating))

action_avgs <-edx%>%
  group_by(userId)%>%
  filter(Action!=0)%>%
  dplyr::summarize(action_bias = mean(Action-mu_rating))

thriller_avgs <-edx%>%
  group_by(userId)%>%
  filter(Thriller!=0)%>%
  dplyr::summarize(thriller_bias = mean(Thriller-mu_rating),)

genre_avgs<-edx%>%
  left_join(drama_avgs, by = 'userId')%>%
  left_join(comedy_avgs, by = 'userId')%>%
  left_join(action_avgs, by = 'userId')%>%
  left_join(thriller_avgs, by = 'userId')%>%
  mutate(Drama = case_when(Drama == 0 ~ 0, TRUE ~ 1),
         Comedy = case_when(Comedy == 0 ~ 0, TRUE ~ 1),
         Action = case_when(Action == 0 ~ 0, TRUE ~ 1),
         Thriller = case_when(Thriller == 0 ~ 0, TRUE ~ 1),
         drama_bias = Drama*drama_bias,
         comedy_bias = Comedy*comedy_bias,
         action_bias = Action*action_bias,
         thriller_bias = Thriller*thriller_bias,
         genre_bias = (drama_bias + comedy_bias + action_bias + thriller_bias)/(Drama+Comedy+Action+Thriller))%>%
  select(userId, movieId, drama_bias, comedy_bias,action_bias,thriller_bias, genre_bias)
```

All the biases were added to the mean rating of all movies to create the predicted rating.Predicted ratings were created on the training data set.

```{r, predicted_ratings}
predicted_ratings <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  left_join(movie_year_avgs, by='movie_year')%>%
  left_join(n_ratings, by='movieId') %>%
  left_join(genre_avgs, by = c('userId','movieId')) %>%
  select(rating, movieId, userId, movie_bias, user_bias, movie_year_bias, n_ratings_bias,
         genre_bias, drama_bias, comedy_bias,action_bias,thriller_bias, y_hat_nratings)%>%
  mutate(yhat_mu_rating = mu_rating,
         yhat_movie_bias = movie_bias+mu_rating,
         yhat_user_bias = user_bias+mu_rating,
         yhat_movie_year_bias = movie_year_bias + mu_rating,
         yhat_genre_bias = genre_bias + mu_rating,
         yhat = genre_bias + movie_year_bias+n_ratings_bias+user_bias+movie_bias+mu_rating,
         yhat_limits = case_when(yhat>=5 ~ 5, yhat<=0 ~ 0, TRUE ~yhat))

head(predicted_ratings)
edx<-edx[complete.cases(predicted_ratings), ]
predicted_ratings<-predicted_ratings[complete.cases(predicted_ratings), ]

```

Then the root mean square error (RMSE) was used to evaluate the success of the predicted rating compared to the actual rating.

```{r,RMSE_formula}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

None of the predictions based on the biases returned a desirable RMSE value. In particular, the Cumulative Bias Model returned a value greater than 1 which is a very poor result. The model performed so poorly because the formula did not apply weights to the biases. Clearly, some of the biases such as the movie bias and user-genre bias have a stronger affect on the final rating.

```{r, RMSE_calculations}
#RMSE calculations for each yhat column
base_rmse <- RMSE(edx$rating,mu_rating) 
movie_bias_rmse <- RMSE(edx$rating, predicted_ratings$yhat_movie_bias) 
user_bias_rmse <- RMSE(edx$rating, predicted_ratings$yhat_user_bias) 
nratings_bias_rmse <- RMSE(edx$rating, predicted_ratings$y_hat_nratings) 
movie_year_bias_rmse <- RMSE(edx$rating, predicted_ratings$yhat_movie_year_bias)
genre_bias_rmse <-RMSE(edx$rating, predicted_ratings$yhat_genre_bias)
cumulative_bias_rmse <- RMSE(edx$rating, predicted_ratings$yhat_limits) 

#store the RMSE results in a data frame
rmse_results <- bind_rows(data_frame(method = "Average Rating", RMSE = base_rmse), 
                          data_frame(method="Movie Bias Model", RMSE = movie_bias_rmse ),
                          data_frame(method="User Bias Model",RMSE = user_bias_rmse ),
                          data_frame(method="Number of Ratings Bias Model",RMSE = nratings_bias_rmse ),
                          data_frame(method="Movie Year Bias",RMSE = movie_year_bias_rmse ),
                          data_frame(method = "User Genre Bias", RMSE = genre_bias_rmse),
                          data_frame(method="Cumulative Bias Model",RMSE = cumulative_bias_rmse ))
rmse_results
```

####Random Forest Model
A random forest model was created to better fit the predictors to the rating. An initial random forest was run on a small percent of the data to do a quick check of processing time, evaluate variable importance, and to select the number of trees.

A new datafram was created containing only the movieId, userId, rating, year values and bias values

```{r, edx_format}
edx_bias<-predicted_ratings%>%
  select('rating','movie_bias','user_bias','n_ratings_bias', 'movie_year_bias','drama_bias','comedy_bias',
         'thriller_bias','action_bias','genre_bias')

edx_bias<-edx_bias[complete.cases(edx_bias), ] #remove NaNs
```

A small random forest model was excuted on a random sample of 0.2% the training data to do a quick check of processing time, evaluate variable importance, and to select Ntrees

```{r, initial_random_forest}
set.seed(1) 
rf_index <- createDataPartition(y = edx_bias$rating, times = 1, p = 0.002, list = FALSE)
x<-as.matrix(edx_bias[rf_index,2:10])
y<-as.matrix(edx_bias[rf_index,1])
fit_rf<-randomForest(x,as.vector(y), ntree = 300) 
varImp(fit_rf)
plot(fit_rf, main = "Random Forest Model")
```

Reviewing the variables in the random forest showed that the number of ratings bias was not very important so it was removed from the dataframe in order to improve processing time.


```{r, remove_nratings}
edx_bias<-edx_bias[,-4]

```

The data is now ready for fitting the final random forest model. The number of trees is 50. The model is being fit on a random sample of 10% of teh training data because of RAM/memory limitations.

```{r, random_forest}
set.seed(1) 
rf_index <- createDataPartition(y = edx_bias$rating, times = 1, p = 0.1, list = FALSE)
x<-as.matrix(edx_bias[rf_index,2:9])
y<-as.matrix(edx_bias[rf_index,1])
fit_rf<-randomForest(x,as.vector(y), ntree= 50)
varImp(fit_rf, scale = TRUE)
fit_rf
```

The test data needed to be updated to match the same format as the training data. This included removing NaN, adding the genre columns, and calculating the bias values.
```{r, format_test_data,include=FALSE}
test<-test%>%filter(str_count(genres,"Drama")==1 |
                      str_count(genres,"Comedy")==1 |
                      str_count(genres,"Action")==1 |
                      str_count(genres,"Thriller")==1)%>%
  mutate(Drama=case_when(str_count(genres,"Drama")==1 ~ rating, TRUE ~ 0),
         Comedy = case_when(str_count(genres,"Comedy")==1 ~ rating, TRUE ~ 0),
         Action=case_when(str_count(genres,"Action")==1 ~ rating, TRUE ~ 0),
         Thriller=case_when(str_count(genres,"Thriller")==1 ~ rating, TRUE ~ 0),
         movie_year = as.integer(str_extract(str_sub(title, -5),"\\d{4}")))

test_movieId<-test%>%
  group_by(movieId) %>% 
  dplyr::summarize(movie_bias = mean(rating - mu_rating))

test_userId <- test %>%
  group_by(userId) %>% 
  dplyr::summarize(user_bias = mean(rating - mu_rating))

movie_year_avgs <- test %>%
  group_by(movie_year) %>% 
  dplyr::summarize(movie_year_bias = mean(rating - mu_rating))

drama_avgs <-test%>%
  group_by(userId)%>%
  filter(Drama!=0)%>%
  dplyr::summarize(drama_bias = mean(Drama-mu_rating))

comedy_avgs <-test%>%
  group_by(userId)%>%
  filter(Comedy!=0)%>%
  dplyr::summarize(comedy_bias = mean(Comedy-mu_rating))

action_avgs <-test%>%
  group_by(userId)%>%
  filter(Action!=0)%>%
  dplyr::summarize(action_bias = mean(Action-mu_rating))

thriller_avgs <-test%>%
  group_by(userId)%>%
  filter(Thriller!=0)%>%
  dplyr::summarize(thriller_bias = mean(Thriller-mu_rating))

test_genre<-test%>%
  left_join(drama_avgs, by = 'userId')%>%
  left_join(comedy_avgs, by = 'userId')%>%
  left_join(action_avgs, by = 'userId')%>%
  left_join(thriller_avgs, by = 'userId')%>%
  mutate(Drama = case_when(Drama == 0 ~ 0, TRUE ~ 1),
         Comedy = case_when(Comedy == 0 ~ 0, TRUE ~ 1),
         Action = case_when(Action == 0 ~ 0, TRUE ~ 1),
         Thriller = case_when(Thriller == 0 ~ 0, TRUE ~ 1),
         drama_bias = Drama*drama_bias,
         comedy_bias = Comedy*comedy_bias,
         action_bias = Action*action_bias,
         thriller_bias = Thriller*thriller_bias,
         genre_bias = (drama_bias + comedy_bias + action_bias + thriller_bias)/(Drama+Comedy+Action+Thriller))%>%
  select(userId, movieId, drama_bias, comedy_bias,action_bias,thriller_bias, genre_bias)


test_bias <- test %>% 
  left_join(test_movieId, by='movieId') %>%
  select(rating, movieId, userId, movie_bias, movie_year)%>%
  left_join(test_userId, by='userId') %>%
  select(rating, movieId, userId, movie_bias, user_bias, movie_year)%>%
  left_join(movie_year_avgs, by = 'movie_year')%>%
  left_join(test_genre, by=c('userId','movieId'))%>%
  select(rating, movie_bias, user_bias, movie_year_bias, drama_bias, comedy_bias,
         action_bias,thriller_bias,genre_bias)

test_bias<-test_bias[complete.cases(test_bias), ] #remove NaNs
head(test_bias)
```

Once the test data was formatted, then the predicted ratings were preticted with the fitted random forest model. 
```{r, test_yhat}
x<-as.matrix(test_bias[,2:9])
y<-as.matrix(test_bias[,1])
y_hat <- predict(fit_rf, x, type = "class")

rf_test_rmse <- RMSE(as.numeric(y_hat),as.numeric(y))
rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "RF model Test Data", RMSE = rf_test_rmse))
rf_test_rmse
```

A histogram of the predicted ratings shows a similar distribution to the actual ratings.
```{r, plot_test_yhat}
y_hat_round <- round_any(y_hat,0.5) 

as.data.frame(y_hat_round)%>%
  ggplot(aes(y_hat_round))+
  geom_histogram()+
  ggtitle("Distribution of Predicted Ratings in Test Data")+
  xlab("Predicted Rating")
```

##RESULTS:
The validation data set was converted into the same format and then the final results were calculated.

```{r, format_validation_data,include=FALSE}

#Convert validation data set into the same format as edx_bias and then use for calculating the final predictions and RMSE
validation<-validation%>%filter(str_count(genres,"Drama")==1 |
                                  str_count(genres,"Comedy")==1 |
                                  str_count(genres,"Action")==1 |
                                  str_count(genres,"Thriller")==1)%>%
  mutate(Drama=case_when(str_count(genres,"Drama")==1 ~ rating, TRUE ~ 0),
         Comedy = case_when(str_count(genres,"Comedy")==1 ~ rating, TRUE ~ 0),
         Action=case_when(str_count(genres,"Action")==1 ~ rating, TRUE ~ 0),
         Thriller=case_when(str_count(genres,"Thriller")==1 ~ rating, TRUE ~ 0))

val_movieId<-validation%>%
  group_by(movieId) %>% 
  dplyr::summarize(movie_bias = mean(rating - mu_rating))

val_userId <- validation %>%
  group_by(userId) %>% 
  dplyr::summarize(user_bias = mean(rating - mu_rating))

movie_year_avgs <- validation %>%
  group_by(movie_year) %>% 
  dplyr::summarize(movie_year_bias = mean(rating - mu_rating))

drama_avgs <-validation%>%
  group_by(userId)%>%
  filter(Drama!=0)%>%
  dplyr::summarize(drama_bias = mean(Drama-mu_rating))

comedy_avgs <-validation%>%
  group_by(userId)%>%
  filter(Comedy!=0)%>%
  dplyr::summarize(comedy_bias = mean(Comedy-mu_rating))

action_avgs <-validation%>%
  group_by(userId)%>%
  filter(Action!=0)%>%
  dplyr::summarize(action_bias = mean(Action-mu_rating))

thriller_avgs <-validation%>%
  group_by(userId)%>%
  filter(Thriller!=0)%>%
  dplyr::summarize(thriller_bias = mean(Thriller-mu_rating))

val_genre<-validation%>%
  left_join(drama_avgs, by = 'userId')%>%
  left_join(comedy_avgs, by = 'userId')%>%
  left_join(action_avgs, by = 'userId')%>%
  left_join(thriller_avgs, by = 'userId')%>%
  mutate(Drama = case_when(Drama == 0 ~ 0, TRUE ~ 1),
         Comedy = case_when(Comedy == 0 ~ 0, TRUE ~ 1),
         Action = case_when(Action == 0 ~ 0, TRUE ~ 1),
         Thriller = case_when(Thriller == 0 ~ 0, TRUE ~ 1),
         drama_bias = Drama*drama_bias,
         comedy_bias = Comedy*comedy_bias,
         action_bias = Action*action_bias,
         thriller_bias = Thriller*thriller_bias,
         genre_bias = (drama_bias + comedy_bias + action_bias + thriller_bias)/(Drama+Comedy+Action+Thriller))%>%
  select(userId, movieId, drama_bias, comedy_bias,action_bias,thriller_bias, genre_bias)

val_bias <- validation %>% 
  left_join(val_movieId, by='movieId') %>%
  select(rating, movieId, userId, movie_bias, movie_year)%>%
  left_join(val_userId, by='userId') %>%
  select(rating, movieId, userId, movie_bias, user_bias, movie_year)%>%
  left_join(movie_year_avgs, by = 'movie_year')%>%
  left_join(val_genre, by=c('userId','movieId'))%>%
  select(rating, movie_bias, user_bias, movie_year_bias, drama_bias, comedy_bias,
         action_bias,thriller_bias,genre_bias)

val_bias<-val_bias[complete.cases(val_bias), ] #remove NaNs
head(val_bias)
```

The predicted ratings for the validation dataset give a RMSE that is well below the required value of 0.86490.

```{r, validation_yhat}
#Create predictions and evaluate on the accuracy and RMSE
x<-as.matrix(val_bias[,2:9])
y<-as.matrix(val_bias[,1])
y_hat <- predict(fit_rf, x, type = "class") 
rf_val_rmse <- RMSE(as.numeric(y),as.numeric(y_hat))
rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "RF model Validation Data", RMSE = rf_val_rmse))
rmse_results

```

Addtionally, a scatter plot reveals a strong correlation between the actual ratings and the predicted ratings.

```{r, y_yhat_chart,echo=FALSE}
y_yhat<-as.data.frame(y)%>%
  mutate(y_hat=y_hat)

y_yhat[1:200,]%>%
  ggplot(aes(y[1:200],y_hat[1:200]))+
  geom_point()+
  xlab("Actual Rating")+
  ylab("Predicted Rating")+
  ggtitle("Predicted vs Actual Ratings")
```

##CONCLUSION:
The random forest model returned an RMSE well below the required value of 0.86490. The solution was created from the exploratory data analysis. The bias predictors for movie ratings, user ratings, and user-genre preferences are major contributors to the low RMSE score. The main limitation to these results was the processing capability of the computer. This prevented the randow forest from being fit to a large percentage of the training data set. Future work could be done to predict movie ratings for a specific user based on how users with similar movie preferences have rated movies.

